#|

Proof that computeFloatSum is DRF:

https://github.com/pandegroup/openmm/blob/master/platforms/cuda/src/kernels/customIntegrator.cu#L1

|#

# Thread blocks and multi dimensional tids

#|

__shared__ within thread-block but not globally, which makes it safe across
groups.


> We make no distinction between shared and global memory (cf. Figure 1) in our
> programming language; from a verification perspective, it suffices to view
> shared memory as being part of global memory (by employing the IDs of groups in
> the calculation of memory addresses).
-- DOI: 10.1145/2743017

|#

# OpenShmem barriers with a subset of tasks, ptp
# (with rdma similar to future and promise), atomic

# syncThread is only block-level

# Declare shared variables
shared sumBuffer, tempBuffer, result;

const
  local blockDim_x,
  global SUM_BUFFER_SIZE,
  local tid
where
  # We must also declare tid as being unique across threads
  # That is: no two threads have the same tid.
  distinct [tid];

let WORK_GROUP_SIZE = 1024; # XXX: it would be great if we could inline a set of values

foreach (index in tid .. SUM_BUFFER_SIZE; index + blockDim_x) {
    ro sumBuffer[index];
}

rw tempBuffer[tid];
foreach (i in 1 .. WORK_GROUP_SIZE; i * 2) {
    sync;
    if (tid%(i*2) == 0 && tid+i < WORK_GROUP_SIZE) {
        ro tempBuffer[tid + i];
        rw tempBuffer[tid];
    }
}
if (tid == 0) {
  ro tempBuffer[0];
  rw result[0];
}
