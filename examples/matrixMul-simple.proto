#|
Source: http://selkie.macalester.edu/csinparallel/modules/GPUProgramming/build/html/CUDA2D/CUDA2D.html#an-example-of-matrix-multiplication
|#

shared Md, Nd, Pd, Mds, Nds;
const
    global Width,
    global blockD,
    # CUDA standard
    local blockIdx.x,
    local threadIdx.x,
    local blockIdx.y,
    local threadIdx.y,
    global blockDim.y,
    global blockDim.x,
    global gridDim.x,
    global gridDim.y,

where blockIdx.x < gridDim.x &&
    blockIdx.y < gridDim.y &&
    threadIdx.x < blockDim.x &&
    threadIdx.y < blockDim.y &&
    distinct [threadIdx.x][threadIdx.y][blockIdx.x][blockIdx.y] &&
    # Kernel assumptions
    blockDim.x == blockDim.y &&
    blockDim.y == blockD &&
    # Assumptions
    pow2(blockD) &&
    #blockD == 512 &&
    Width == blockD * 1024
    #Width == 512 * 1024
    ;

# keep track of column index of the Pd element using thread index
let x = threadIdx.x + blockIdx.x * blockDim.x; # x is column
# keep track of row index of the Pd element using thread index
let y = threadIdx.y + blockIdx.y * blockDim.y; # y is row

if (x < Width) {

  # Loop over the Md and Nd block dimension required to compute the Pd element
  foreach (m in 0 .. Width/blockD) {

    # collaboratively loading of Md and Nd blocks into shared memory
    rw Mds[blockIdx.x][blockIdx.y][threadIdx.y][threadIdx.x];
    ro Md[y * Width + (m * blockD + threadIdx.x)];
    rw Nds[blockIdx.x][blockIdx.y][threadIdx.y][threadIdx.x];
    ro Md[(m * blockD + threadIdx.y) * Width + x];
    sync;

    # keep track of the running sum
    foreach (k in 0.. blockD) {
      ro Mds[blockIdx.x][blockIdx.y][threadIdx.y][k];
      ro Nds[blockIdx.x][blockIdx.y][k][threadIdx.x];
    }
    sync;
  }

  # write back to the global memory
  rw Pd[y * Width + x];

}