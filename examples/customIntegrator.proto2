#|

Proof that computeFloatSum is DRF:

https://github.com/pandegroup/openmm/blob/master/platforms/cuda/src/kernels/customIntegrator.cu#L1

|#

# Thread blocks and multi dimensional tids

#|

__shared__ within thread-block but not globally, which makes it safe across
groups.


> We make no distinction between shared and global memory (cf. Figure 1) in our
> programming language; from a verification perspective, it suffices to view
> shared memory as being part of global memory (by employing the IDs of groups in
> the calculation of memory addresses).
-- DOI: 10.1145/2743017

|#

# OpenShmem barriers with a subset of tasks, ptp
# (with rdma similar to future and promise), atomic

# syncThread is only block-level

# Declare shared variables
shared sumBuffer, tempBuffer, result;

const
  local blockDim_x,
  global SUM_BUFFER_SIZE,
  global WORK_GROUP_SIZE,
  local $tid;

# We must also declare $tid as being unique across threads
# That is: no two threads have the same $tid.
assert 1@$tid != 2@$tid;

foreach index < SUM_BUFFER_SIZE {
  assert index >= $tid;
  assert (index - $tid) % blockDim_x == 0;
  ro sumBuffer[index];
}; # We require a semi after a loop

rw tempBuffer[$tid];
foreach i < WORK_GROUP_SIZE {
  assert i >= 1;
  assert pow2(i);
  sync;
  ro tempBuffer[$tid + i]  if ($tid%(i*2) == 0 && $tid+i < WORK_GROUP_SIZE);
  rw tempBuffer[$tid] if ($tid%(i*2) == 0 && $tid+i < WORK_GROUP_SIZE);
};

ro tempBuffer[0] if $tid == 0;
rw result[0] if $tid == 0;
